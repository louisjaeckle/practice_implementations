{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea54985",
   "metadata": {},
   "source": [
    "### Random Forest Algorithm, as I understand it\n",
    "\n",
    "Don't expect it to be perfect, or even good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70e71aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1625648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gini score for grouping\n",
    "def get_gini(groups,classes):\n",
    "    #groups - each element is [feature 1, feature 2,..., class]\n",
    "    #classes- list of unique classes in data\n",
    "    gini = 0.0\n",
    "    total_size = float(sum([len(group) for group in groups]))\n",
    "    for group in groups:\n",
    "        group_size = float(len(group))\n",
    "        if group_size==0.0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        class_freq = [[member[-1] for member in group].count(cl) for cl in classes]\n",
    "        class_probs = [float(freq)/group_size for freq in class_freq]\n",
    "        group_gini = sum([(prob*(1.0-prob)) for prob in class_probs])\n",
    "        gini+=group_gini*(group_size/total_size)\n",
    "    return gini\n",
    "\n",
    "#binary split data into classes based on feature at ind with best gini\n",
    "def optimal_split_feature(data,classes,ind):\n",
    "    assert ind<len(data[0])-1#ensure ind is valid feature index\n",
    "    \n",
    "    best_gini = 2.0\n",
    "    best_threshold = data[0][ind]\n",
    "    best_groups = []\n",
    "    for member in data:\n",
    "        left_group = [row for row in data if row[ind]<member[ind]]\n",
    "        right_group = [row for row in data if row[ind]>=member[ind]]\n",
    "        gini = get_gini([left_group,right_group],classes)\n",
    "        if gini<best_gini:\n",
    "            best_gini = gini\n",
    "            best_threshold = member[ind]\n",
    "            best_groups = [left_group,right_group]\n",
    "    return best_threshold,best_gini,best_groups\n",
    "\n",
    "#find optimal feature+split\n",
    "def optimal_split_data(data,classes,features):\n",
    "    best_gini = 2.0\n",
    "    best_threshold = 0.0\n",
    "    best_feature = 0\n",
    "    best_groups = []\n",
    "    \n",
    "    for feature_ind in features:\n",
    "        threshold, gini, groups = optimal_split_feature(data,classes,feature_ind)\n",
    "        if gini<best_gini:\n",
    "            best_gini = gini\n",
    "            best_threshold = threshold\n",
    "            best_feature = feature_ind\n",
    "            best_groups = groups\n",
    "    \n",
    "    return best_feature, best_threshold, best_groups\n",
    "\n",
    "#choose random subset of data members\n",
    "def get_random_tree_data(data,fraction = 0.7):\n",
    "    #fraction - expected fraction of data to use\n",
    "    tree_data = [row for row in data if np.random.uniform()<fraction]\n",
    "    return tree_data\n",
    "\n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, features,classes,max_depth):\n",
    "        #features - list of feature indices to use when building tree\n",
    "        #classes - list of available classes\n",
    "        self.features = features\n",
    "        self.classes = classes\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.decision_tree = []\n",
    "    \n",
    "    #build tree using data\n",
    "    def build_tree(self,data):\n",
    "        \n",
    "        def recursive_build(depth,rem_data):\n",
    "            if len(rem_data)==0:\n",
    "                return self.classes[0]#if there are no data left, return arbitrary class. This is probably bad\n",
    "            if rem_data==1 or depth>=self.max_depth:\n",
    "                class_mode = self.classes[0]\n",
    "                mode_freq = 0\n",
    "                for class_val in self.classes:\n",
    "                    class_freq = [member[-1] for member in rem_data].count(class_val)\n",
    "                    if class_freq>mode_freq:\n",
    "                        class_mode = class_val\n",
    "                        mode_freq = class_freq\n",
    "                return class_mode\n",
    "            \n",
    "            best_feature,best_threshold,best_groups = optimal_split_data(data,self.classes,self.features)\n",
    "            l_node = recursive_build(depth+1,best_groups[0])\n",
    "            r_node = recursive_build(depth+1,best_groups[1])\n",
    "            return [best_feature,best_threshold,l_node,r_node]\n",
    "        \n",
    "        self.decision_tree = recursive_build(0,data)\n",
    "    \n",
    "    #get item prediction from tree\n",
    "    def query_tree(self,item):\n",
    "        rem_tree = copy.deepcopy(self.decision_tree)\n",
    "        while type(rem_tree) is list:\n",
    "            if item[rem_tree[0]]<rem_tree[1]:\n",
    "                rem_tree = rem_tree[2]\n",
    "            else:\n",
    "                rem_tree = rem_tree[3]\n",
    "        return rem_tree\n",
    "\n",
    "\n",
    "    \n",
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self,data,n_trees,max_depth=7):\n",
    "        self.classes = list(set([member[-1] for member in data]))\n",
    "        \n",
    "        self.trees = []\n",
    "        features_per_tree = int(math.sqrt(len(data[0])-1)+0.5)\n",
    "        for t in range(n_trees):\n",
    "            feature_indices = np.random.randint(0,len(data[0])-1,size=(features_per_tree,))\n",
    "            self.trees.append(DecisionTree(feature_indices,self.classes,max_depth))\n",
    "            self.trees[-1].build_tree(get_random_tree_data(data))\n",
    "    \n",
    "    #get item prediction from forest\n",
    "    def query_forest(self,item):\n",
    "        tree_guesses = [tree.query_tree(item) for tree in self.trees]\n",
    "        class_mode = self.classes[0]\n",
    "        mode_freq = 0\n",
    "        for class_val in self.classes:\n",
    "            class_freq = tree_guesses.count(class_val)\n",
    "            if class_freq>mode_freq:\n",
    "                class_mode = class_val\n",
    "                mode_freq = class_freq\n",
    "        return class_mode\n",
    "    \n",
    "    #evaluate forest performance on set of data\n",
    "    def eval_forest(self,data):\n",
    "        predictions = [self.query_forest(member) for member in data]\n",
    "        correct = 0\n",
    "        for i in range(len(data)):\n",
    "            if predictions[i]==data[i][-1]:\n",
    "                correct+=1\n",
    "        print(f'{correct} out of {len(data)} ({100.0*float(correct)/float(len(data))}%) correct, with {len(self.trees)} trees')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17bd5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('sonar.all-data') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data_row = [float(entry.strip()) for entry in row[:-1]]\n",
    "        data_row.append(row[-1].strip())#class\n",
    "        data.append(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7bda4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "forests = [RandomForest(data,n_trees) for n_trees in [1,3,5,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ade0660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'R', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'R', 'R', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'M', 'R', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'R', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M']\n",
      "139 out of 208 (66.82692307692308%) correct, with 1 trees\n",
      "['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'M', 'R', 'M', 'R', 'M', 'M', 'M', 'R', 'M', 'R', 'M', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'M', 'R', 'R']\n",
      "122 out of 208 (58.65384615384615%) correct, with 3 trees\n",
      "['R', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'R', 'R', 'M', 'R', 'M', 'M', 'R', 'M', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'M', 'R', 'M', 'M', 'M', 'M', 'R', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M']\n",
      "163 out of 208 (78.36538461538461%) correct, with 5 trees\n",
      "['M', 'R', 'M', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'R', 'M', 'R', 'M', 'R', 'R', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M']\n",
      "162 out of 208 (77.88461538461539%) correct, with 10 trees\n"
     ]
    }
   ],
   "source": [
    "for forest in forests:\n",
    "    forest.eval_forest(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
